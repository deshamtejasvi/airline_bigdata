<workflow-app xmlns="uri:oozie:workflow:0.2" name="DataWorkflow-wf">
   <start to="program1" />
<action name="program1">
      <map-reduce>
         <job-tracker>${jobTracker}</job-tracker>
         <name-node>${nameNode}</name-node>
         <prepare>
            <delete path="${nameNode}/user/${wf:user()}/output/${outputDir}" />
         </prepare>
         <configuration>
            <property>
               <name>mapred.mapper.new-api</name>
               <value>true</value>
            </property>
            <property>
               <name>mapred.reducer.new-api</name>
               <value>true</value>
            </property>
            <property>
               <name>mapred.job.queue.name</name>
               <value>${queueName}</value>
            </property>
            <property>
               <name>mapreduce.map.class</name>
               <value>FlightDelay$Map</value>
            </property>
            <property>
               <name>mapreduce.reduce.class</name>
               <value>FlightDelay$Reduce</value>
            </property>
            <property>
               <name>mapred.output.key.class</name>
               <value>org.apache.hadoop.io.Text</value>
            </property>
            <property>
               <name>mapred.output.value.class</name>
               <value>org.apache.hadoop.io.Text</value>
            </property>
            <property>
               <name>mapred.map.tasks</name>
               <value>1</value>
            </property>
            <property>
               <name>mapred.input.dir</name>
               <value>/user/${wf:user()}/input</value>
            </property>
            <property>
               <name>mapred.output.dir</name>
               <value>/user/${wf:user()}/output/${outputDir}</value>
            </property>
         </configuration>
      </map-reduce>
      <ok to="program2" />
      <error to="fail" />
   </action>
   

<action name="program2">
      <map-reduce>
         <job-tracker>${jobTracker}</job-tracker>
         <name-node>${nameNode}</name-node>
         <prepare>
            <delete path="${nameNode}/user/${wf:user()}/output/${outputDir}" />
         </prepare>
         <configuration>
            <property>
               <name>mapred.mapper.new-api</name>
               <value>true</value>
            </property>
            <property>
               <name>mapred.reducer.new-api</name>
               <value>true</value>
            </property>
            <property>
               <name>mapred.job.queue.name</name>
               <value>${queueName}</value>
            </property>
            <property>
               <name>mapreduce.map.class</name>
               <value>TaxiAverage$mapper</value>
            </property>
            <property>
               <name>mapreduce.reduce.class</name>
               <value>TaxiAverage$reducer</value>
            </property>
            <property>
               <name>mapred.output.key.class</name>
               <value>org.apache.hadoop.io.Text</value>
            </property>
            <property>
               <name>mapred.output.value.class</name>
               <value>org.apache.hadoop.io.Text</value>
            </property>
            <property>
               <name>mapred.map.tasks</name>
               <value>1</value>
            </property>
            <property>
               <name>mapred.input.dir</name>
               <value>/user/${wf:user()}/input</value>
            </property>
            <property>
               <name>mapred.output.dir</name>
               <value>/user/${wf:user()}/output/dataworkflow1</value>
            </property>
         </configuration>
      </map-reduce>
      <ok to="program3" />
      <error to="fail" />
   </action>

<action name="program3">
      <map-reduce>
         <job-tracker>${jobTracker}</job-tracker>
         <name-node>${nameNode}</name-node>
         <prepare>
            <delete path="${nameNode}/user/${wf:user()}/output/${outputDir}" />
         </prepare>
         <configuration>
            <property>
               <name>mapred.mapper.new-api</name>
               <value>true</value>
            </property>
            <property>
               <name>mapred.reducer.new-api</name>
               <value>true</value>
            </property>
            <property>
               <name>mapred.job.queue.name</name>
               <value>${queueName}</value>
            </property>
            <property>
               <name>mapreduce.map.class</name>
               <value>Cancellation$mapper</value>
            </property>
            <property>
               <name>mapreduce.reduce.class</name>
               <value>Cancellation$reducer</value>
            </property>
            <property>
               <name>mapred.output.key.class</name>
               <value>org.apache.hadoop.io.Text</value>
            </property>
            <property>
               <name>mapred.output.value.class</name>
               <value>org.apache.hadoop.io.LongWritable</value>
            </property>
            <property>
               <name>mapred.map.tasks</name>
               <value>1</value>
            </property>
            <property>
               <name>mapred.input.dir</name>
               <value>/user/${wf:user()}/input</value>
            </property>
            <property>
               <name>mapred.output.dir</name>
               <value>/user/${wf:user()}/output/dataworkflowOut</value>
            </property>
         </configuration>
      </map-reduce>
      <ok to="end" />
      <error to="fail" />
   </action>

   <kill name="fail">
      <message>Map/Reduce failed, error message[${wf:errorMessage(wf:lastErrorNode())}]</message>
   </kill>
   <end name="end" />
</workflow-app>
